---
title: "Multiple Regression WEIGHT"
author: "Jonathan Teo"
date: "November 14, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
```{r}
bears <- read.csv(file="BEARS.csv",header = TRUE)
```
  
## make a multiple regression model predicting LENGTH, start with full model using p-value approach   
  
```{r}
fullup <- lm(WEIGHT~ .,data=bears)
summary.lm(fullup)
```
  
###Take out HEADWTH  
  
```{r}
MODL7 <- lm(WEIGHT~ .-HEADWTH,data=bears)
summary.lm(MODL7)
```
  
###Now take out LENGTH  
  
```{r}
MODL6 <- lm(WEIGHT~ .-HEADWTH-LENGTH,data=bears)
summary.lm(MODL6)
```
  
###Remove MONTH next
  
```{r}
MODL5 <- lm(WEIGHT~ .-HEADWTH-LENGTH-MONTH,data=bears)
summary.lm(MODL5)
```
  
###Now remove SEX    
  
```{r}
MODL4 <- lm(WEIGHT~ .-HEADWTH-LENGTH-MONTH-SEX,data=bears)
summary.lm(MODL4)
```
  
The Adjusted R-Squared got lower instead of getting higher so we know it is time to stop. 
  
###AdjR^2 Started going from 4 to 3 - so stop at 4
  


## make a multiple regression model predicting LENGTH, start with full model using Adj$R^2$ approach 
  


##Model LENGTH ~ .     ("." is shorthand for all variables )
  
```{r}
fullup <- lm(WEIGHT~ .,data=bears)
summary.lm(fullup)
```
  
```{r}
fullup.1 <- lm(WEIGHT~ . -AGE,data=bears)
summary.lm(fullup.1)
```
  
```{r}
fullup.2<- lm(WEIGHT~ .-MONTH,data=bears)
summary.lm(fullup.2)
```
  
```{r}
fullup.3<- lm(WEIGHT~ .-SEX,data=bears)
summary.lm(fullup.3)
```
  
```{r}
fullup.4 <- lm(WEIGHT~ . -HEADLEN,data=bears)
summary.lm(fullup.4)
```
  
```{r}
fullup.5<- lm(WEIGHT~ .-HEADWTH,data=bears)
summary.lm(fullup.5)
```
  

```{r}
fullup.6<- lm(WEIGHT~ .-NECK,data=bears)
summary.lm(fullup.6)
```
  
```{r}
fullup.7<- lm(LENGTH~ .-CHEST,data=bears)
summary.lm(fullup.7)
```
  

```{r}
fullup.8<- lm(WEIGHT~ .-LENGTH,data=bears)
summary.lm(fullup.8)
```
  
  
###At this point we pick the best one, then from there we would take up with that model and one-by-one take out one of the other explanitory variables and select the best of those - and repeat  The one where we took out HEADWTH is best  with Adj$R^2$ .9395

```{r}
fullup.1.2<- lm(WEIGHT~ .-HEADWTH-MONTH,data=bears)
summary.lm(fullup.1.2)
```
  
```{r}
fullup.1.3<- lm(WEIGHT~ .-HEADLEN-SEX,data=bears)
summary.lm(fullup.1.3)
```
  
```{r}
fullup.1.4 <- lm(WEIGHT~ . -HEADLEN-AGE,data=bears)
summary.lm(fullup.1.4)
```
  
```{r}
fullup.1.5<- lm(WEIGHT~ .-HEADLEN-HEADWTH,data=bears)
summary.lm(fullup.1.5)
```
  
```{r}
fullup.1.6<- lm(WEIGHT~ .-HEADLEN-NECK,data=bears)
summary.lm(fullup.1.6)
```
  
```{r}
fullup.1.7<- lm(WEIGHT~ .-HEADLEN-CHEST,data=bears)
summary.lm(fullup.1.7)
```
  
```{r}
fullup.1.8<- lm(WEIGHT~ .-HEADLEN-LENGTH,data=bears)
summary.lm(fullup.1.8)
```
  
###At this point we pick the best one again, then from there we would take up with that model and one-by-one take out one of the other explanitory variables and select the best of those - and repeat  This time we have  (HEADLEN and MONTH) because it's Adj$R^2$ is .9399   
  
####This is a pain we must have a better way  
  
#now automate


```{r}
library(leaps)
regsubsets.out <-
    regsubsets(WEIGHT ~ .,
               data = bears,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

summary.out <- summary(regsubsets.out)
as.data.frame(summary.out$outmat)
library(car)
subsets(regsubsets.out,statistic="adjr2",legend="bottomright",main="Adjusted R^2")
```
  
##Which is best??  

```{r}
which.max(summary.out$adjr2)
```
  
```{r}
summary.out$which[5,]
```
  
```{r}
best.model <- lm(WEIGHT~AGE+SEX+HEADLEN+NECK+CHEST,data=bears)
summary(best.model)
```
  
